{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_text(dir_name):\n",
    "    text_dic = {}    \n",
    "    elsevier = os.listdir(dir_name+'/')\n",
    "    for e in tqdm(elsevier):\n",
    "        with open(dir_name+'/'+e, 'r', encoding='utf-8') as f:\n",
    "            data = f.readlines()\n",
    "            doi = data[0][:-1]\n",
    "            start_words = ['Graphical abstract','Abstract', 'Corresponding author', 'Correspondence to:', 'Introduction', 'Keywords']\n",
    "            s_find = 0\n",
    "            for s in start_words:\n",
    "                if s in data[1]:\n",
    "                    start = data[1].find(s)\n",
    "                    s_find = 1\n",
    "            if s_find == 0:\n",
    "                start = 0\n",
    "            if 'Reference' in data[1]:\n",
    "                end = data[1].rfind('Reference')\n",
    "            else:\n",
    "                end = len(data[1])\n",
    "            fulltext = data[1][start:end]                \n",
    "            text_dic[e]={}\n",
    "            text_dic[e]['text']=fulltext\n",
    "            text_dic[e]['doi']=doi\n",
    "    return text_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemdataextractor import Document\n",
    "from tqdm import tqdm\n",
    "from chemdataextractor.doc import Paragraph\n",
    "import re\n",
    "\n",
    "def get_material(sens):\n",
    "    punc = ['–', ':', '/', '-']\n",
    "    sen_mat = {}\n",
    "    abb_sum = {}\n",
    "    para = Paragraph(sens)\n",
    "    for sen in para.sentences:\n",
    "        cems_dic = {}\n",
    "        tokens = sen.tokens\n",
    "        doc = Document(sen.text)\n",
    "        tmp = []\n",
    "        if doc.cems:\n",
    "            for c in doc.cems:\n",
    "                if c.text.count(' ')<5:\n",
    "                    tmp.append(c.start)\n",
    "                    cems_dic[c.start] = {}\n",
    "                    cems_dic[c.start]['name'] = c.text\n",
    "                    cems_dic[c.start]['end'] = c.end   \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # collect fullname position and replace\n",
    "        for tok in tokens:\n",
    "            for t in tmp:\n",
    "                # only word contain material name and conj punc can be fullname\n",
    "                flag1 = 0\n",
    "                flag2 = 0\n",
    "                if cems_dic[t]['name'] in tok.text and cems_dic[t]['name']!=tok.text:\n",
    "                    flag1 = 1\n",
    "                for p in punc:\n",
    "                    if p in tok.text[:-1]:\n",
    "                        flag2 = 1\n",
    "                if flag1 == 1 and flag2 == 1:\n",
    "                    # print('this', tok.text, cems_dic[t]['name'])\n",
    "                    try:\n",
    "                        pos_list = re.finditer(tok.text, sen.text)\n",
    "                    except:\n",
    "                        continue\n",
    "                    for pos in pos_list:\n",
    "                        if pos.start() <= t and pos.end() >= cems_dic[t]['end']:\n",
    "                            del cems_dic[t]\n",
    "                            tmp.remove(t)\n",
    "                            cems_dic[pos.start()]={}\n",
    "                            cems_dic[pos.start()]['name'] = tok.text\n",
    "                            cems_dic[pos.start()]['end'] = pos.end()\n",
    "                                   \n",
    "        sen_mat[sen.text] = {}\n",
    "        sen_mat[sen.text]['materials'] = {}\n",
    "        for c in cems_dic.keys():\n",
    "            sen_mat[sen.text]['materials'][cems_dic[c]['name']] = [c, cems_dic[c]['end']]\n",
    "        abb = doc.abbreviation_definitions\n",
    "        if abb:\n",
    "            for tup in abb:\n",
    "                for name in sen_mat[sen.text]['materials'].keys():\n",
    "                    if tup[1][0] in name:\n",
    "                        if name not in abb_sum.keys():\n",
    "                            abb_sum[name] = [tup[0][0]]\n",
    "                        else:\n",
    "                            abb_sum[name].append(tup[0][0])\n",
    "    return sen_mat, abb_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个字典是储存原句和里面具体material names和Position\n",
    "# 一个字典是汇总对子及其doi\n",
    "\n",
    "def return_dict(topic_dic):\n",
    "    sen_sum = {}\n",
    "    pair_sum = {}\n",
    "    abb_sum = {}\n",
    "    mat_sum = {}\n",
    "    for o in tqdm(list(topic_dic.keys())):\n",
    "        t = topic_dic[o]['text']\n",
    "        sen_mat, abb_mat = get_material(t)\n",
    "        for s in sen_mat.keys():\n",
    "            sen_sum[s] = sen_mat[s]\n",
    "            sen_sum[s]['doi'] = topic_dic[o]['doi']\n",
    "        for abb in abb_mat.keys():\n",
    "            if abb not in pair_sum.keys():\n",
    "                pair_sum[abb] = {}\n",
    "                for new in abb_mat[abb]:\n",
    "                    pair_sum[abb][new] = [topic_dic[o]['doi']]\n",
    "            else:\n",
    "                for new in abb_mat[abb]:\n",
    "                    if new not in pair_sum[abb].keys():\n",
    "                        pair_sum[abb][new] = [topic_dic[o]['doi']]\n",
    "                    else:\n",
    "                        pair_sum[abb][new].append(topic_dic[o]['doi'])\n",
    "    return sen_sum, pair_sum                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581/581 [00:00<00:00, 928.14it/s]\n",
      "100%|██████████| 581/581 [13:33<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# Anti-soiling_Elsevier_53\n",
    "# Antistatic_Elsevier_156\n",
    "# Hydrophilic_Elsevier_8921\n",
    "# Hydrophobic_Elsevier_13677\n",
    "# Oleophobic_Elsevier_581\n",
    "# Omniphobic_Elsevier_143\n",
    "# Photocatalytic_Elsevier_13437\n",
    "# SC_Elesever_2044\n",
    "import os\n",
    "import json\n",
    "\n",
    "dir_name = 'Oleophobic_Elsevier_581'\n",
    "ol_dict = get_text(dir_name)\n",
    "sen_dict, pair_dict = return_dict(ol_dict)\n",
    "full_mat_dict = {}\n",
    "# 一个字典是总结Material names数量 withour abb, store a version\n",
    "for s in sen_dict.keys():\n",
    "    for mat in sen_dict[s]['materials']:\n",
    "        if mat not in full_mat_dict.keys():\n",
    "            full_mat_dict[mat] = 1\n",
    "        else:\n",
    "            full_mat_dict[mat] += 1\n",
    "sorted_full = sorted(full_mat_dict.items(), key=lambda item:item[1], reverse=True)\n",
    "\n",
    "if not os.path.exists('material_names/'+dir_name):\n",
    "    os.makedirs('material_names/'+dir_name)\n",
    "    \n",
    "json_str = json.dumps(sen_dict, indent=4)\n",
    "with open('material_names/'+dir_name+'/sen_dict.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(json_str)\n",
    "    \n",
    "json_str = json.dumps(pair_dict, indent=4)\n",
    "with open('material_names/'+dir_name+'/pair_dict.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(json_str)\n",
    "    \n",
    "with open('material_names/'+dir_name+'/full_mat_dict.txt', 'w', encoding='utf-8') as f:\n",
    "    for i, sf in enumerate(sorted_full):\n",
    "        f.write(str(i+1)+'\\t'+sf[0]+'\\t'+str(sf[1]))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine material names and abbreviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarize pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nfor f in final_pairs.keys():\\n    for abb in final_pairs[f].keys():\\n        flag = 1\\n        for c in f:\\n            if c.lower() not in abb.lower():\\n                flag = 0\\n        if flag == 0:\\n            print(f, abb)\\n    # print(f, final_pairs[f])\\n \\njson_str = json.dumps(final_pairs, indent=4)\\nwith open('final_pairs.json', 'w', encoding='utf-8') as json_file:\\n    json_file.write(json_str)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "large_pairs = {}\n",
    "for topic in os.listdir('material_names'):\n",
    "    with open('material_names/'+topic+'/pair_dict.json', 'r', encoding='utf-8') as f:\n",
    "        pair_dict = json.load(f)\n",
    "        for p in pair_dict.keys():\n",
    "            if p not in large_pairs:\n",
    "                large_pairs[p] = pair_dict[p]\n",
    "            else:\n",
    "                for abb in pair_dict[p].keys():\n",
    "                    if abb not in large_pairs[p].keys():\n",
    "                        large_pairs[p][abb] = pair_dict[p][abb]\n",
    "                    else:\n",
    "                        for doi in pair_dict[p][abb]:\n",
    "                            if doi not in large_pairs[p][abb]:\n",
    "                                large_pairs[p][abb].append(doi)\n",
    "\n",
    "final_pairs =   {}                              \n",
    "for lp in large_pairs.keys():     \n",
    "    max_len = 0\n",
    "    for abb in large_pairs[lp].keys():\n",
    "        if len(large_pairs[lp][abb]) > max_len:\n",
    "            max_len = len(large_pairs[lp][abb])\n",
    "            max_abb = abb\n",
    "    if max_len > 5:\n",
    "        if max_abb not in final_pairs.keys():\n",
    "            final_pairs[max_abb] = {}\n",
    "            final_pairs[max_abb][lp] = max_len\n",
    "        else:\n",
    "            final_pairs[max_abb][lp] = max_len\n",
    "            \n",
    "''' \n",
    "for f in final_pairs.keys():\n",
    "    for abb in final_pairs[f].keys():\n",
    "        flag = 1\n",
    "        for c in f:\n",
    "            if c.lower() not in abb.lower():\n",
    "                flag = 0\n",
    "        if flag == 0:\n",
    "            print(f, abb)\n",
    "    # print(f, final_pairs[f])\n",
    " \n",
    "json_str = json.dumps(final_pairs, indent=4)\n",
    "with open('final_pairs.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(json_str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELEMENTS = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K',\n",
    "                'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr',\n",
    "                'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I',\n",
    "                'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb',\n",
    "                'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr',\n",
    "                'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf',\n",
    "                'Db', 'Sg', 'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn', 'Nh', 'Fl', 'Mc', 'Lv', 'Ts', 'Og', 'Uue']\n",
    "\n",
    "ELEMENT_NAMES = ['hydrogen', 'helium', 'lithium', 'beryllium', 'boron', 'carbon', 'nitrogen', 'oxygen', 'fluorine',\n",
    "                     'neon', 'sodium', 'magnesium', 'aluminium', 'silicon', 'phosphorus', 'sulfur', 'chlorine', 'argon',\n",
    "                     'potassium', 'calcium', 'scandium', 'titanium', 'vanadium', 'chromium', 'manganese', 'iron',\n",
    "                     'cobalt', 'nickel', 'copper', 'zinc', 'gallium', 'germanium', 'arsenic', 'selenium', 'bromine',\n",
    "                     'krypton', 'rubidium', 'strontium', 'yttrium', 'zirconium', 'niobium', 'molybdenum', 'technetium',\n",
    "                     'ruthenium', 'rhodium', 'palladium', 'silver', 'cadmium', 'indium', 'tin', 'antimony', 'tellurium',\n",
    "                     'iodine', 'xenon', 'cesium', 'barium', 'lanthanum', 'cerium', 'praseodymium', 'neodymium',\n",
    "                     'promethium', 'samarium', 'europium', 'gadolinium', 'terbium', 'dysprosium', 'holmium', 'erbium',\n",
    "                     'thulium', 'ytterbium', 'lutetium', 'hafnium', 'tantalum', 'tungsten', 'rhenium', 'osmium',\n",
    "                     'iridium', 'platinum', 'gold', 'mercury', 'thallium', 'lead', 'bismuth', 'polonium', 'astatine',\n",
    "                     'radon', 'francium', 'radium', 'actinium', 'thorium', 'protactinium', 'uranium', 'neptunium',\n",
    "                     'plutonium', 'americium', 'curium', 'berkelium', 'californium', 'einsteinium', 'fermium',\n",
    "                     'mendelevium', 'nobelium', 'lawrencium', 'rutherfordium', 'dubnium', 'seaborgium', 'bohrium',\n",
    "                     'hassium', 'meitnerium', 'darmstadtium', 'roentgenium', 'copernicium', 'nihonium', 'flerovium',\n",
    "                     'moscovium', 'livermorium', 'tennessine', 'oganesson', 'ununennium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dic(sen_dict, pairs):\n",
    "    full_mat_dict = {}\n",
    "    for s in sen_dict.keys():\n",
    "        for mat in sen_dict[s]['materials']:\n",
    "            if mat not in full_mat_dict.keys():\n",
    "                full_mat_dict[mat] = 1\n",
    "            else:\n",
    "                full_mat_dict[mat] += 1\n",
    "    tmp_dict = {}\n",
    "    store_ = []\n",
    "    for f in full_mat_dict.keys():\n",
    "        if f in pairs.keys():\n",
    "            tmp_dict[f] = {}\n",
    "            tmp_dict[f][f] = full_mat_dict[f]\n",
    "            store_.append(f)\n",
    "            for pk in pairs[f].keys():\n",
    "                if pk in full_mat_dict.keys():\n",
    "                    tmp_dict[f][pk] = full_mat_dict[pk]\n",
    "                    store_.append(pk)\n",
    "        else:\n",
    "            if f in ELEMENTS:\n",
    "                tmp_dict[f] = {}\n",
    "                tmp_dict[f][f] = full_mat_dict[f]\n",
    "                store_.append(f)\n",
    "                idx = ELEMENTS.index(f)\n",
    "                full_f = ELEMENT_NAMES[idx]\n",
    "                if full_f in full_mat_dict.keys():\n",
    "                    tmp_dict[f][full_f] = full_mat_dict[full_f]\n",
    "                    store_.append(full_f)\n",
    "                upper = full_f[0].upper()+full_f[1:]\n",
    "                if upper in full_mat_dict.keys():\n",
    "                    tmp_dict[f][upper] = full_mat_dict[upper]\n",
    "                    store_.append(upper)\n",
    "    for f in full_mat_dict.keys():\n",
    "        if f not in store_:\n",
    "            tmp_dict[f] = {}\n",
    "            tmp_dict[f]['num'] = full_mat_dict[f]\n",
    "    for t in tmp_dict.keys():\n",
    "        if 'num' not in tmp_dict[t].keys():\n",
    "            num = 0\n",
    "            for k in tmp_dict[t].keys():\n",
    "                num += tmp_dict[t][k]\n",
    "            tmp_dict[t]['num'] = num\n",
    "    return tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anti-soiling_Elsevier_53\n",
    "# Antistatic_Elsevier_156\n",
    "# Hydrophilic_Elsevier_8921\n",
    "# Hydrophobic_Elsevier_13677\n",
    "# Oleophobic_Elsevier_581\n",
    "# Omniphobic_Elsevier_143\n",
    "# Photocatalytic_Elsevier_13437\n",
    "# SC_Elesever_2044\n",
    "import os\n",
    "import json\n",
    "\n",
    "dir_name = 'SC_Elesever_2044'\n",
    "with open('material_names/'+dir_name+'/sen_dict.json', 'r', encoding='utf-8') as f:\n",
    "    sen_dict = json.load(f)\n",
    "with open('final_pairs.json', 'r', encoding='utf-8') as f:\n",
    "    pairs = json.load(f)    \n",
    "comb_dict = combine_dic(sen_dict, pairs)\n",
    "\n",
    "json_str = json.dumps(comb_dict, indent=4)\n",
    "with open('material_names/'+dir_name+'/com_dict.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(json_str)\n",
    "    \n",
    "sorted_com = sorted(comb_dict.items(), key=lambda item:item[1]['num'], reverse=True)\n",
    "with open('material_names/'+dir_name+'/com_mat_dict.txt', 'w', encoding='utf-8') as f:\n",
    "    for i, sf in enumerate(sorted_com):\n",
    "        if sf[1]['num'] > 1:\n",
    "            if len(sf[1].keys())>1:\n",
    "                f.write(str(i+1)+'\\t'+sf[0]+'\\t'+str(sf[1]['num'])+'\\t')\n",
    "                del sf[1]['num']\n",
    "                f.write(str(sf[1]))\n",
    "            else:\n",
    "                f.write(str(i+1)+'\\t'+sf[0]+'\\t'+str(sf[1]['num']))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
